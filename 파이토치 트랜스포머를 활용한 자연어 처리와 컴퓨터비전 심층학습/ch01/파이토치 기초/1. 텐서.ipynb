{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1\n",
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available()) \n",
    "print(torch.backends.mps.is_available()) # gpu대신 mps사용 / mps확인\n",
    "print(torch.backends.mps.is_built()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mps 사용 설정\n",
    "import torch\n",
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 텐서 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([1, 2, 3])\n",
      "tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.tensor([1, 2, 3])) # 입력된 데이터를 복사해 텐서로 변환하는 함수 (의도하지 않은 자료형으로 변경될 수 있음) 자동으로 자료형 할당\n",
    "print(torch.Tensor([[1, 2, 3], [4, 5, 6]])) # 텐서의 기본형 텐서 인스턴스를 생성하는 클래스 (인스턴스를 생성하기 때문에 비어 있는 경우 비어있는 텐서 생성) 권장\n",
    "print(torch.LongTensor([1, 2, 3]))\n",
    "print(torch.FloatTensor([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 텐서 속성\n",
    "- 형태 (shape): 텐서의 차원\n",
    "- 자료형 (dtype) : 텐서에 할당된 데이터 형식\n",
    "- 장치 (device) : gpu가속 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2418, 0.6633]], device='mps:0')\n",
      "torch.Size([1, 2])\n",
      "torch.float32\n",
      "mps:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"mps\") # mps디바이스 설정\n",
    "\n",
    "tensor = torch.rand(1, 2).to(device) # 호출\n",
    "print(tensor)\n",
    "print(tensor.shape)\n",
    "print(tensor.dtype)\n",
    "print(tensor.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 차원 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6068, 0.6250]])\n",
      "torch.Size([1, 2])\n",
      "tensor([[0.6068],\n",
      "        [0.6250]])\n",
      "torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tensor = torch.rand(1, 2)\n",
    "print(tensor)\n",
    "print(tensor.shape)\n",
    "\n",
    "tensor = tensor.reshape(2, 1)\n",
    "print(tensor)\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 자료형 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2317, 0.1166, 0.9567],\n",
      "        [0.0297, 0.1065, 0.6254],\n",
      "        [0.2282, 0.7065, 0.5028]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tensor = torch.rand((3, 3), dtype=torch.float)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 장치 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n",
      "tensor([1., 2., 3.])\n",
      "tensor([1., 2., 3.], device='mps:0')\n",
      "tensor([[0.3711]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# 현재 M1사용 중 cuda x\n",
    "import torch\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "cpu = torch.FloatTensor([1, 2, 3])\n",
    "mps = torch.FloatTensor([1, 2, 3]).to(device)\n",
    "tensor = torch.rand((1, 1), device=device)\n",
    "print(device)\n",
    "print(cpu)\n",
    "print(mps)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 장치 변환\n",
    "- cpu장치를 사용하는 텐서와 다른 장치를 사용하는 텐서는 상호 간 연산이 불가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([1., 2., 3.], device='mps:0')\n",
      "tensor([1., 2., 3.])\n",
      "tensor([1., 2., 3.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "cpu = torch.FloatTensor([1,2,3])\n",
    "mps = cpu.to(device)\n",
    "mps2cpu = mps.cpu()\n",
    "cpu2mps = cpu.to(device)\n",
    "print(cpu)\n",
    "print(mps)\n",
    "print(mps2cpu)\n",
    "print(cpu2mps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 넘파이 배열의 텐서 변환\n",
    "- 넘파이나 다른 라이브러리 데이터를 파이토치에 활용하려면 텐서 형식으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3], dtype=torch.uint8)\n",
      "tensor([1., 2., 3.])\n",
      "tensor([1, 2, 3], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "ndarray = np.array([1, 2, 3], dtype=np.uint8)\n",
    "print(torch.tensor(ndarray))\n",
    "print(torch.Tensor(ndarray))\n",
    "print(torch.from_numpy(ndarray))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 텐서의 넘파이 배열 변환\n",
    "- 추론된 결과를 후처리하거나 결괏값을 활용할 때 사용\n",
    "- 추론/평가 단계에서는 gradient decent가 필요없기 때문에 (매개변수 변경 x, 주어진 입력에 대한 출력만 계산함)\n",
    "    - 이로인해 연산량을 줄일 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3.]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tensor = torch.FloatTensor([1,2,3]).to(torch.device('mps')) # 텐서는 모든 연산은 추적해 기록 이 기록을 통해 뎍전파 등의 연산 진행\n",
    "ndarray = tensor.detach().cpu().numpy() # detach(): 현재 연산 그래프에서 분리된 새로운 텐서 변환 / cpu(): 메모리 텐서를 cpu메모리로 이동 / numpy(): numpy배열로 변환\n",
    "print(ndarray)\n",
    "print(type(ndarray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
