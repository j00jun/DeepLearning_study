{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 가중치 초기화 종류\n",
    "\n",
    "- 상수 초기화\n",
    "    - 대칭 파괴 문제\n",
    "    \n",
    "- 무작위 초기화\n",
    "\n",
    "- 제이비어 & 글로럿 초기화\n",
    "    - 균등 분포나 정규 분포를 사용해 가중치를 초기화 하는 방법 - 시그모이드나 하이퍼볼릭 탄젠트를 활성화 함수로 사용하는 네트워크에서 효과적\n",
    "\n",
    "- 카이밍 & 허 초기화\n",
    "    - 균등 분포나 정규 분포를 사용해 가중치를 초기화하는 방법 - 순방향 네트워크에서 가중치를 초기화할 때 효과적 ( 현재 계층의 입력 뉴런 수를 기반으로만 가중치를 초기화)\n",
    "\n",
    "- 직교 초기화\n",
    "    - 특잇값 분해를 활용 - LSTM, GRU와 같은 순환 신경망에 사용 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(1, 2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.fc = nn.Linear(2, 1)\n",
    "        self._init_weights()\n",
    "\n",
    "    # 제이비어 초기화\n",
    "    def _init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.layer[0].weight) # 첫번 값만 가중치 초기화 진행 (nn.Linear) / activation 함수는 가중치와 편향을 갖지 않음\n",
    "        self.layer[0].bias.data.fill_(0.01) # 편향을 0.01로 채움\n",
    "\n",
    "        nn.init.xavier_uniform_(self.fc.weight)\n",
    "        self.fc.bias.data.fill_(0.01)\n",
    "\n",
    "model = Net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply: Linear(in_features=1, out_features=2, bias=True)\n",
      "Apply: Sigmoid()\n",
      "Apply: Sequential(\n",
      "  (0): Linear(in_features=1, out_features=2, bias=True)\n",
      "  (1): Sigmoid()\n",
      ")\n",
      "Apply: Linear(in_features=2, out_features=1, bias=True)\n",
      "Apply: Net(\n",
      "  (layer): Sequential(\n",
      "    (0): Linear(in_features=1, out_features=2, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      "  (fc): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 가중치 초기화 (모듈화)\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(1, 2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.fc = nn.Linear(2, 1)\n",
    "        self.apply(self._init_weights) # apply함수로 self(인스턴스)에서 시작하여 모든 서브 모듈 재귀적 방문 -> 각 서브 모듈 apply함수 인자로 받은 _init_weights 함수 호출 서브 모듈 자체 인자로 넘김\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear): # 선형 변환 함수인지 확인\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "            nn.init.constant_(module.bias, 0.01)\n",
    "        print(f'Apply: {module}')\n",
    "    \n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
