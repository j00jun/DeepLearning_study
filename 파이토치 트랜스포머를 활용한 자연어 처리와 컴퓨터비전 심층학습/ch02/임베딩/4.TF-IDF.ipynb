{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF\n",
    "- 텍스트 문서에서 특정 단어의 중요도를 계산하는 방법\n",
    "- 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적인 가중치를 의미 ( BoW(Bag-df-Words (문서를 단어의 순서를 무시하고 단순히 단어의 출현 빈도만을 고려하여 표현))에 가중치 부여하는 방법)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 단어 빈도(TF)\n",
    "- 문서 내에서 특정 단어의 빈도수를 내타내는 값\n",
    "\n",
    "#### 문서 빈도(DF)\n",
    "- 한 단어가 얼마나 많은 문서에 나타나는지 의미\n",
    "\n",
    "#### 역문서 빈도(IDF)\n",
    "- 전체 문서 수 / 문서 빈도 로그를 취한 값\n",
    "- 문서 집합에서 해당 단어가 얼마나 드물게 등장하는지를 나타내는 지표\n",
    "- 문서 빈도가 높을수록 해당 단어가 일반적이고 상대적으로 중요하지 않다는 의미가 됨 -> 문서 빈도의 역수를 취해 단어 빈도수가 적을수록 IDF 값이 커지게 보정\n",
    "\n",
    "#### TF-IDF\n",
    "- 앞선 문서 빈도와 역문서 빈도를 곱한 값\n",
    "- 문서 내에 단어가 자주 등장하지만, 전체 문서 내에 해당 단어가 적게 등장하면 TF-IDF 값은 커짐\n",
    "- 즉 한 문서 내에서는 빈번하게 등장하지만, 전체 문서 집합에서는 드물게 등장하는 경우 값이 커짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF 클래스\n",
    "import sklearn\n",
    "\n",
    "tfidf_vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(\n",
    "    input='content', # 입력될 데이터 형태\n",
    "    encoding = 'utf-8', # 사용할 텍스트 인코딩 값\n",
    "    lowercase = True, # 입력 데이터 소문자 변환 여부\n",
    "    stop_words = None, # 불용어 처리 (입력된 단어들은 단어 사전 추가 x)\n",
    "    ngram_range = (1,1), # n그램 범위 (최대값, 최소값)\n",
    "    max_df=1.0, # 전체 문서 중 일정 횟수 이상 등장한 단어 불용어 처리\n",
    "    min_df=1, # 전체 문서 중 일정 횟수 미만으로 등장한 단어를 불용어 처리\n",
    "    vocabulary=None, #미리 구축한 단어사전이 있다면 해당 단어 사전 사용\n",
    "    smooth_idf=True, #분모처리 (IDF계산 시 특정 단어가 한번도 등장하지 않는 경우 0이기 때문에 분모에 1을 더하는데 기능 여부)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF 계산\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = [\n",
    "    'That movie is famous movie',\n",
    "    'I like that actor',\n",
    "    \"I don't like that actor\"\n",
    "]\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorizer.fit(corpus) # 학습\n",
    "tfidf_matrix = tfidf_vectorizer.transform(corpus) #데이터 변환 (fit_transform메서드를 통해 학습과 변환 동시에도 가능) / 실제 문서(corpus)를 TF-IDF 값이 포함된 벡터 공간으로 변환\n",
    "\n",
    "# 학습과 변환을 한 번에 수행하여 TF-IDF 행렬을 생성\n",
    "# tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "print(tfidf_matrix.toarray()) # 넘파이 배열로 변환 / 각 행은하나의 문서에 해당, 각 열은 단어를 의미\n",
    "print(tfidf_vectorizer.vocabulary_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
